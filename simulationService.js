const { Pinecone } = require('@pinecone-database/pinecone');
const OpenAI = require('openai');
const fs = require('fs');
const path = require('path');

// Initialize OpenAI
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

// Initialize Pinecone
const pinecone = new Pinecone({
    apiKey: process.env.PINECONE_API_KEY
});

const INDEX_NAME = process.env.PINECONE_INDEX_NAME || 'formation-apl';
const NAMESPACE = process.env.PINECONE_NAMESPACE || 'info-to-rag';

// ====================================================================
// SIMULATION DATA LOADING
// ====================================================================

/**
 * Load simulation scenarios from JSON
 */
function loadSimulations() {
    try {
        const simulationsPath = path.join(__dirname, '../public/simulations_apl.json');
        const data = fs.readFileSync(simulationsPath, 'utf8');
        return JSON.parse(data);
    } catch (error) {
        console.error('Error loading simulations:', error);
        throw error;
    }
}

/**
 * Get a specific simulation by ID
 */
function getSimulation(simulationId) {
    const data = loadSimulations();
    const simulation = data.simulations.find(s => s.simulation_id === simulationId);
    
    if (!simulation) {
        throw new Error(`Simulation ${simulationId} not found`);
    }
    
    return simulation;
}

// ====================================================================
// RAG CONTEXT RETRIEVAL (For Gemini system instruction)
// ====================================================================

/**
 * Search RAG context for simulation
 * Used to build Gemini's system instruction with CAF rules
 */
async function searchSimulationContext(moduleReference, query, topK = 5) {
    try {
        console.log(`üìö [RAG] Searching context for module: ${moduleReference}, query: "${query}"`);
        
        // Generate embedding for the query
        const embeddingResponse = await openai.embeddings.create({
            model: 'text-embedding-3-small',
            input: `${moduleReference} ${query}`
        });

        const queryEmbedding = embeddingResponse.data[0].embedding;

        // Search in Pinecone
        const index = pinecone.index(INDEX_NAME);
        const queryResponse = await index.namespace(NAMESPACE).query({
            vector: queryEmbedding,
            topK: topK,
            includeMetadata: true
        });

        // Extract and format results
        const contexts = queryResponse.matches.map(match => ({
            text: match.metadata.text,
            score: match.score,
            module: match.metadata.module,
            section: match.metadata.section
        }));

        console.log(`‚úÖ [RAG] Retrieved ${contexts.length} context(s)`);
        return contexts;
        
    } catch (error) {
        console.error('‚ö†Ô∏è [RAG] Search failed for simulation:', error.message);
        return []; // Return empty array if RAG fails (simulation can still work)
    }
}

// ====================================================================
// SIMULATION EVALUATION - Nouvelle version simplifi√©e
// ====================================================================

/**
 * Evaluate conversation with comparison between ideal and actual responses
 * For each allocataire question, generate ideal agent response and compare
 */
async function evaluateConversation(conversationHistory, scenarioContext = {}) {
    try {
        console.log(`üìä [Evaluation] Analyzing conversation with ${conversationHistory.length} messages...`);
        
        // Get RAG context for official rules (reduced to 3 for token limit)
        const ragContexts = await searchSimulationContext(
            'module_1',
            'diff√©rence APL ALF ALS conditions grossesse famille basculement',
            3
        );

        // Truncate RAG text to max 2000 characters to save tokens
        const ragContextText = ragContexts
            .map((ctx, i) => `[Doc ${i + 1}] ${ctx.text.substring(0, 600)}`)
            .join('\n\n');

        // Build conversation text
        const conversationText = conversationHistory
            .map((msg, idx) => {
                const role = msg.role === 'user' ? 'AGENT CAF (vous)' : 'ALLOCATAIRE (Sophie)';
                return `[Message ${idx + 1}] ${role}:\n${msg.content}`;
            })
            .join('\n\n');

        // Build evaluation prompt (DETAILED VERSION with question extraction)
        const evaluationPrompt = `√âvaluateur CAF expert. Analyse d√©taill√©e de la conversation entre agent CAF et allocataire.

üìã CONTEXTE ALLOCATAIRE:
${scenarioContext.allocataire ? `${scenarioContext.allocataire.prenom} ${scenarioContext.allocataire.nom}` : 'Allocataire'}
Probl√®me: ${scenarioContext.problem ? scenarioContext.problem.substring(0, 200) : 'N/A'}

üìö DOCUMENTATION CAF (R√âF√âRENCE):
${ragContextText || 'N/A'}

üí¨ CONVERSATION COMPL√àTE:
${conversationText}

üéØ TA MISSION:

1. IDENTIFIE TOUTES LES QUESTIONS/INQUI√âTUDES de l'allocataire dans la conversation
2. Pour CHAQUE question identifi√©e:
   - G√©n√®re la R√âPONSE ID√âALE bas√©e sur la doc CAF
   - Extrait la R√âPONSE R√âELLE de l'agent (cite exactement ce qu'il a dit)
   - Compare les deux et √©value (exactitude, clart√©, empathie)
   - Identifie ce qui MANQUE (chiffres, dates, d√©tails techniques)

3. ANALYSE GLOBALE:
   - D√©tails techniques/chiffr√©s manquants
   - Questions de clarification que l'agent aurait d√ª poser
   - Informations importantes non v√©rifi√©es

RETOURNE JSON STRICTEMENT:
{
  "questions_identifiees": [
    {
      "numero": 1,
      "question_allocataire": "La question ou inqui√©tude EXACTE exprim√©e par l'allocataire",
      "contexte_question": "Dans quel contexte de la conversation",
      "reponse_ideale": {
        "contenu": "Ce que l'agent aurait d√ª r√©pondre selon la doc CAF (d√©taill√©)",
        "elements_cles": ["√âl√©ment 1", "√âl√©ment 2", "√âl√©ment 3"],
        "chiffres_dates_requis": ["Juin 2025", "205‚Ç¨/mois", "etc."]
      },
      "reponse_reelle": {
        "contenu": "Ce que l'agent a R√âELLEMENT dit (citation exacte de la conversation)",
        "elements_mentionnes": ["Ce qui a √©t√© dit"],
        "elements_manquants": ["Ce qui manque"]
      },
      "feedback_comparaison": {
        "exactitude_technique": "correct/partiellement correct/incorrect",
        "justesse_chiffres": "pr√©cis/approximatif/absent/incorrect",
        "clarte_explication": "clair/moyennement clair/confus",
        "empathie": "pr√©sente/partielle/absente",
        "score": 0-100,
        "commentaire_detaille": "Analyse de l'√©cart entre id√©al et r√©el, ce qui manque"
      }
    }
  ],
  "informations_manquantes_globales": {
    "details_techniques_non_mentionnes": ["R√®gle X non expliqu√©e", "Condition Y oubli√©e"],
    "chiffres_dates_absents": ["Date pr√©cise du basculement", "Montant estim√©"],
    "questions_clarification_oubliees": ["Aurait d√ª demander la date de d√©claration", "Aurait d√ª v√©rifier le conventionnement"]
  },
  "synthese_finale": {
    "points_forts": ["Ce qui a √©t√© bien fait"],
    "points_amelioration": ["Ce qui doit √™tre am√©lior√©"],
    "competences": {
      "maitrise_technique": {"score": 0-100, "commentaire": "Analyse"},
      "precision_chiffres_dates": {"score": 0-100, "commentaire": "Analyse"},
      "communication": {"score": 0-100, "commentaire": "Analyse"},
      "relationnel": {"score": 0-100, "commentaire": "Analyse"}
    },
    "score_global": 0-100,
    "niveau": "D√©butant/Interm√©diaire/Confirm√©/Expert",
    "recommandations_prioritaires": ["Action 1", "Action 2", "Action 3"]
  }
}

‚ö†Ô∏è R√àGLES CRITIQUES POUR LE JSON:
- JSON valide UNIQUEMENT, sans markdown
- √âchappe TOUS les guillemets dans les cha√Ænes avec \"
- Pas de retours √† la ligne dans les cha√Ænes JSON
- Pas de virgules trailing
- Structure compl√®te et ferm√©e
- Sois TR√àS d√©taill√© dans l'extraction des r√©ponses r√©elles`;

        // Call OpenAI for evaluation (using gpt-4o for complex JSON generation)
        console.log(`ü§ñ [Evaluation] Calling OpenAI gpt-4o (better for complex JSON)...`);
        const completion = await openai.chat.completions.create({
            model: 'gpt-4o',
            messages: [
                {
                    role: 'system',
                    content: 'Tu es un √©valuateur expert CAF. Retourne UNIQUEMENT du JSON valide et complet.'
                },
                {
                    role: 'user',
                    content: evaluationPrompt
                }
            ],
            response_format: { type: "json_object" },
            temperature: 0.2
        });

        const responseText = completion.choices[0].message.content.trim();
        console.log(`‚úÖ [Evaluation] OpenAI response received (${responseText.length} chars)`);
        
        // Parse JSON with improved error handling
        let evaluation;
        try {
            // With response_format json_object, the response should be clean JSON
            evaluation = JSON.parse(responseText);
            console.log(`‚úÖ [Evaluation] JSON parsed successfully. Score global: ${evaluation.synthese_finale?.score_global || evaluation.synthese?.score_global}/100`);
        } catch (parseError) {
            console.error('‚ùå [Evaluation] Failed to parse JSON');
            console.error('Parse error:', parseError.message);
            console.error('Response length:', responseText.length);
            console.error('Response text (first 1000 chars):', responseText.substring(0, 1000));
            console.error('Response text (last 500 chars):', responseText.substring(Math.max(0, responseText.length - 500)));
            
            // Try to extract partial data if possible
            try {
                // Try to find and parse just the synthese if the full JSON fails
                const syntheseMatch = responseText.match(/"synthese_finale"\s*:\s*\{[^}]*"score_global"\s*:\s*(\d+)/);
                if (syntheseMatch) {
                    console.warn('‚ö†Ô∏è [Evaluation] Using fallback: extracted partial data');
                    evaluation = {
                        questions_identifiees: [],
                        informations_manquantes_globales: {},
                        synthese_finale: {
                            score_global: parseInt(syntheseMatch[1]),
                            niveau: 'Interm√©diaire',
                            points_forts: ['Analyse partielle disponible'],
                            points_amelioration: ['R√©ponse JSON incompl√®te - erreur technique'],
                            competences: {},
                            recommandations_prioritaires: ['V√©rifier la r√©ponse compl√®te']
                        }
                    };
                } else {
                    throw parseError;
                }
            } catch (fallbackError) {
                throw new Error('Invalid JSON response from evaluation: ' + parseError.message);
            }
        }

        return evaluation;

    } catch (error) {
        console.error('‚ùå [Evaluation] Error:', error);
        throw error;
    }
}

/**
 * Answer assistant question using RAG
 */
async function answerAssistantQuestion(question, moduleNumber, scenarioContext) {
    try {
        console.log(`ü§ñ [Assistant] Question: "${question}" for Module ${moduleNumber}`);
        
        // Search RAG context for the module
        const contexts = await searchSimulationContext(
            `module_${moduleNumber}`,
            question,
            5
        );

        // Build RAG context text
        const ragContextText = contexts
            .map((ctx, i) => `[R√®gle ${i + 1}] ${ctx.text}`)
            .join('\n\n');

        // Build prompt for assistant
        const assistantPrompt = `Tu es un assistant expert de la CAF sp√©cialis√© dans les aides au logement (APL, ALF, ALS).

üìö DOCUMENTATION OFFICIELLE CAF (Module ${moduleNumber}) :
${ragContextText}

${scenarioContext ? `üìã CONTEXTE DU SC√âNARIO EN COURS :
Allocataire : ${scenarioContext.allocataire?.prenom} ${scenarioContext.allocataire?.nom}
Probl√®me : ${scenarioContext.problem_statement?.substring(0, 200)}...

` : ''}‚ùì QUESTION DE L'AGENT CAF :
"${question}"

üéØ TA MISSION :
R√©ponds de mani√®re PR√âCISE, CLAIRE et P√âDAGOGIQUE √† la question de l'agent.
- Utilise UNIQUEMENT les informations de la documentation officielle ci-dessus
- Cite les r√®gles pr√©cises et les pages si n√©cessaire
- Donne des exemples concrets si pertinent
- Structure ta r√©ponse avec des puces ou des paragraphes courts
- Sois PR√âCIS sur les dates, montants, conditions

‚ö†Ô∏è IMPORTANT :
- Si la question n'est pas couverte par la documentation ‚Üí dis-le clairement
- Reste factuel et bas√© sur les r√®gles officielles
- Aide l'agent √† comprendre pour qu'il puisse expliquer √† l'allocataire`;

        // Call OpenAI for answer (using o4-mini)
        const completion = await openai.chat.completions.create({
            model: 'o4-mini',
            messages: [
                {
                    role: 'user',
                    content: assistantPrompt
                }
            ]
        });

        // o4-mini peut retourner le contenu dans reasoning ou content
        let answer = '';
        if (completion.choices[0].message.content) {
            answer = completion.choices[0].message.content.trim();
        } else if (completion.choices[0].message.reasoning) {
            answer = completion.choices[0].message.reasoning.trim();
        }
        
        console.log(`‚úÖ [Assistant] Answer generated (${answer.length} chars)`);

        return answer;

    } catch (error) {
        console.error('‚ùå [Assistant] Error:', error);
        throw error;
    }
}

/**
 * Generate real-time co-pilot recommendations
 */
async function generateCoPilotRecommendations(allocataireMessage, conversationHistory, moduleNumber) {
    try {
        console.log(`üß≠ [Co-Pilot] Analyzing message for Module ${moduleNumber}`);
        
        // Search RAG context for the module
        const contexts = await searchSimulationContext(
            `module_${moduleNumber}`,
            allocataireMessage,
            3 // Top 3 most relevant documents
        );

        // Build RAG context text
        const ragContextText = contexts
            .map((ctx, i) => `[R√®gle ${i + 1}] ${ctx.text}`)
            .join('\n\n');

        // Build conversation history text
        const historyText = conversationHistory
            .map(msg => `${msg.role === 'user' ? 'Agent CAF' : 'Allocataire'}: ${msg.content}`)
            .join('\n');

        // Build co-pilot prompt - SIMPLE ET INTELLIGENT
        const coPilotPrompt = `Tu es un assistant IA qui aide un agent CAF pendant une conversation avec un allocataire.

üìú CONVERSATION COMPL√àTE :
${historyText}

üó£Ô∏è DERNI√àRE PHRASE DE L'ALLOCATAIRE :
"${allocataireMessage}"

üìö DOCUMENTATION CAF (pour r√©f√©rence) :
${ragContextText}

üéØ √âTAPE 1 - CHECKLIST OBLIGATOIRE :
V√©rifie dans la CONVERSATION (pas dans la documentation) si ces infos ont √©t√© EXPLICITEMENT dites :
- Type d'aide actuel (APL/ALF/ALS) : OUI ‚úÖ ou NON ‚ùå
- Situation familiale pr√©cise : OUI ‚úÖ ou NON ‚ùå

üéØ √âTAPE 2 - D√âCISION STRICTE :
- Si Type d'aide = ‚ùå (PAS mentionn√©) ‚Üí OBLIGATOIREMENT type: "questions" pour le demander
- Si Type d'aide = ‚úÖ (mentionn√©) ‚Üí type: "responses" pour r√©pondre √† la question

‚ö†Ô∏è R√àGLE ABSOLUE CRITIQUE :
- JAMAIS parler d'APL/ALF/ALS dans tes recommandations si le type d'aide n'a PAS √©t√© dit
- JAMAIS supposer "passage ALS‚ÜíALF" si "ALS" n'a pas √©t√© mentionn√©
- Si tu ne sais pas quel type d'aide ‚Üí DEMANDE d'abord (questions)

üéØ √âTAPE 3 - FORMAT DES RECOMMANDATIONS :
MAUVAIS ‚ùå : "Expliquer la diff√©rence ALF/ALS"
BON ‚úÖ : "ALF pour famille (g√©n√©ralement plus √©lev√©e) | ALS pour isol√©/couple sans enfant"

MAUVAIS ‚ùå : "Rassurer l'allocataire"
BON ‚úÖ : "Le changement est automatique, aucun risque de perte d'aide pendant la transition"

MAUVAIS ‚ùå : "Expliquer le basculement"
BON ‚úÖ : "Basculement ALS‚ÜíALF au 5√®me mois de grossesse (automatique, aucune d√©marche)"

‚Üí Donne l'INFORMATION CONCR√àTE que l'agent peut dire directement √† l'allocataire
‚Üí Utilise des CHIFFRES, DATES, R√àGLES PR√âCISES de la documentation
‚Üí L'agent doit pouvoir LIRE tes recommandations mot pour mot
‚Üí MAX 2 ITEMS (JAMAIS 3 ou plus)

Format JSON STRICT :
{
  "type": "questions" | "responses" | "both",
  "items": ["Info concr√®te 1 (max 25 mots)", "Info concr√®te 2 (max 25 mots)"]
}

ATTENTION : Le tableau "items" doit contenir EXACTEMENT 2 √©l√©ments maximum.`;

        // Call OpenAI for recommendations (using o4-mini)
        const completion = await openai.chat.completions.create({
            model: 'o4-mini',
            messages: [
                {
                    role: 'user',
                    content: coPilotPrompt
                }
            ]
        });

        // o4-mini peut retourner le contenu dans reasoning ou content
        let responseText = '';
        if (completion.choices[0].message.content) {
            responseText = completion.choices[0].message.content.trim();
        } else if (completion.choices[0].message.reasoning) {
            responseText = completion.choices[0].message.reasoning.trim();
        }
        
        // Parse JSON
        let recommendations;
        try {
            // Clean markdown code blocks
            let cleanedResponse = responseText
                .replace(/```json\n?/g, '')
                .replace(/```\n?/g, '')
                .trim();
            
            // Find JSON object
            const firstBrace = cleanedResponse.indexOf('{');
            const lastBrace = cleanedResponse.lastIndexOf('}');
            
            if (firstBrace !== -1 && lastBrace !== -1) {
                cleanedResponse = cleanedResponse.substring(firstBrace, lastBrace + 1);
            }
            
            // Remove trailing commas
            cleanedResponse = cleanedResponse.replace(/,(\s*[}\]])/g, '$1');
            
            recommendations = JSON.parse(cleanedResponse);
            
            // Ensure max 2 items
            if (recommendations.items && recommendations.items.length > 2) {
                recommendations.items = recommendations.items.slice(0, 2);
            }
            
            console.log(`‚úÖ [Co-Pilot] Recommendations parsed successfully`);
        } catch (parseError) {
            console.error('‚ùå [Co-Pilot] JSON parse error:', parseError.message);
            // Return fallback recommendations
            recommendations = {
                type: "both",
                items: ["Demander plus de d√©tails sur la situation", "V√©rifier les conditions d'√©ligibilit√©"]
            };
        }

        return recommendations;

    } catch (error) {
        console.error('‚ùå [Co-Pilot] Error:', error);
        throw error;
    }
}

/**
 * Generate call summary for phone assistant
 */
async function generateCallSummary(conversation, situation) {
    try {
        console.log(`üìù [Call Summary] Analyzing conversation...`);
        
        // Build conversation text
        const conversationText = conversation
            .map(msg => `${msg.role === 'user' ? 'Allocataire' : 'Assistant'}: ${msg.content}`)
            .join('\n');

        // Build prompt for summary generation
        const summaryPrompt = `Tu es un expert en synth√®se d'appels CAF.

üìû CONVERSATION T√âL√âPHONIQUE :
${conversationText}

üéØ SITUATION CHOISIE PAR L'ALLOCATAIRE :
${situation ? `${situation.title} - ${situation.description}` : 'Non sp√©cifi√©e'}

üìù TA MISSION :
G√©n√®re une NOTE DE DOSSIER professionnelle et structur√©e pour l'agent CAF qui prendra le relais.

FORMAT JSON OBLIGATOIRE :
{
  "identity": "Nom et pr√©nom de l'allocataire (ou 'Non communiqu√©e' si absent)",
  "reason": "Motif de l'appel en 1-2 phrases claires",
  "information_collected": [
    "Info 1 collect√©e",
    "Info 2 collect√©e",
    "..."
  ],
  "missing_information": [
    "Info manquante 1",
    "Info manquante 2",
    "..."
  ],
  "recommended_actions": [
    "Action recommand√©e 1",
    "Action recommand√©e 2",
    "..."
  ]
}

R√àGLES :
- Sois CONCIS et FACTUEL
- Liste TOUTES les informations collect√©es
- Identifie ce qui MANQUE pour traiter le dossier
- Propose des actions CONCR√àTES pour l'agent

G√©n√®re UNIQUEMENT le JSON, rien d'autre.`;

        // Call OpenAI
        const completion = await openai.chat.completions.create({
            model: 'gpt-3.5-turbo',
            messages: [
                {
                    role: 'system',
                    content: 'Tu es un expert en synth√®se d\'appels CAF. G√©n√®re des notes de dossier structur√©es en JSON uniquement.'
                },
                {
                    role: 'user',
                    content: summaryPrompt
                }
            ],
            temperature: 0.3,
        });

        let summary;
        try {
            const responseText = completion.choices[0].message.content.trim();
            console.log(`üìù [Call Summary] Raw response:`, responseText.substring(0, 200));
            
            // Extract JSON from response
            let cleanedResponse = responseText;
            if (cleanedResponse.startsWith('```json')) {
                cleanedResponse = cleanedResponse.replace(/```json\n?/g, '').replace(/```\n?$/g, '');
            } else if (cleanedResponse.startsWith('```')) {
                cleanedResponse = cleanedResponse.replace(/```\n?/g, '');
            }
            
            summary = JSON.parse(cleanedResponse);
            console.log(`‚úÖ [Call Summary] Summary parsed successfully`);
        } catch (parseError) {
            console.error('‚ùå [Call Summary] JSON parse error:', parseError.message);
            // Return fallback summary
            summary = {
                identity: "Non communiqu√©e",
                reason: "Demande concernant les aides au logement",
                information_collected: ["Conversation enregistr√©e"],
                missing_information: ["Identit√© compl√®te", "D√©tails de la situation"],
                recommended_actions: ["Recontacter l'allocataire pour compl√©ter les informations"]
            };
        }

        return summary;

    } catch (error) {
        console.error('‚ùå [Call Summary] Error:', error);
        throw error;
    }
}

// ====================================================================
// EXPORTS
// ====================================================================

module.exports = {
    loadSimulations,
    getSimulation,
    searchSimulationContext,
    evaluateConversation,
    answerAssistantQuestion,
    generateCoPilotRecommendations,
    generateCallSummary
};

// ====================================================================
// NOTE: The following functions have been REMOVED (obsolete):
// - generateAllocataireResponse() ‚Üí Gemini Live API now handles this
// - generateAudio() ‚Üí Gemini Live API includes TTS
// - transcribeAudio() ‚Üí Gemini Live API includes STT
// All voice chat functionality is now handled by Gemini WebSocket API
// ====================================================================
