const { Pinecone } = require('@pinecone-database/pinecone');
const OpenAI = require('openai');

// Initialize Pinecone
const pinecone = new Pinecone({
    apiKey: process.env.PINECONE_API_KEY
});

// Initialize OpenAI
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

const INDEX_NAME = process.env.PINECONE_INDEX_NAME;
const NAMESPACE = process.env.PINECONE_NAMESPACE;

/**
 * Generate embedding for a text using OpenAI
 */
async function generateEmbedding(text) {
    try {
        const response = await openai.embeddings.create({
            model: 'text-embedding-3-small',
            input: text,
        });
        return response.data[0].embedding;
    } catch (error) {
        console.error('Error generating embedding:', error);
        throw error;
    }
}

/**
 * Search for relevant context in Pinecone for exercise evaluation
 */
async function searchExerciseContext(question, correctAnswer, topK = 5) {
    try {
        // Combine question and correct answer for better context retrieval
        const searchQuery = `${question} ${correctAnswer}`;
        const questionEmbedding = await generateEmbedding(searchQuery);

        // Search in Pinecone
        const index = pinecone.index(INDEX_NAME);
        const queryResponse = await index.namespace(NAMESPACE).query({
            vector: questionEmbedding,
            topK: topK,
            includeMetadata: true
        });

        // Extract and format results
        const contexts = queryResponse.matches.map(match => ({
            text: match.metadata.text,
            score: match.score,
            module: match.metadata.module,
            section: match.metadata.section
        }));

        return contexts;
    } catch (error) {
        console.error('âš ï¸ Pinecone search failed for exercise:', error.message);
        return [];
    }
}

/**
 * Evaluate user's answer for QCM (Multiple Choice Questions)
 * Simplified: exact matching + detailed feedback with calculations
 */
async function evaluateAnswer(exerciseData, userAnswer, history = []) {
    try {
        const { question, correct_answer, detailed_explanation, calculation_details, options } = exerciseData;

        // QCM: Simple exact matching
        const isCorrect = userAnswer.trim().toUpperCase() === correct_answer.trim().toUpperCase();

        console.log(`ðŸ“ QCM Ã‰valuation: ${userAnswer} ${isCorrect ? 'âœ… correct' : 'âŒ incorrect'} (attendu: ${correct_answer})`);

        // Get RAG context for sources
        const contexts = await searchExerciseContext(question, correct_answer);

        // Find the selected and correct options text
        const selectedOptionObj = options?.find(opt => opt.id.toUpperCase() === userAnswer.trim().toUpperCase());
        const correctOptionObj = options?.find(opt => opt.id.toUpperCase() === correct_answer.trim().toUpperCase());

        // Build concise feedback (detailed explanation will be shown separately in UI)
        let feedback = '';
        if (isCorrect) {
            feedback = `ðŸŽ‰ Parfait ! Vous maÃ®trisez ce concept.`;
        } else {
            feedback = `Cette rÃ©ponse n'est pas correcte.\n\n`;
            feedback += `Vous avez choisi : **${selectedOptionObj?.text || userAnswer}**\n\n`;
            feedback += `La bonne rÃ©ponse Ã©tait : **${correctOptionObj?.text || correct_answer}**`;
        }

        // Return direct QCM evaluation result
        return {
            is_correct: isCorrect,
            score: isCorrect ? 100 : 0,
            feedback: feedback,
            sources: contexts.slice(0, 3).map(ctx => ({
                module: ctx.module,
                section: ctx.section,
                score: ctx.score
            }))
        };

    } catch (error) {
        console.error('Error evaluating answer:', error);
        throw error;
    }
}

// OLD COMPLEX EVALUATION CODE BELOW (kept for reference but not used)
/*
        const evaluationPrompt = `Tu es un CORRECTEUR CAF EXTRÃŠMEMENT STRICT et RIGOUREUX. Ta mission est d'Ã©valuer avec une PRÃ‰CISION ABSOLUE.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“š CONTEXTE DOCUMENTAIRE OFFICIEL (SOURCE DE VÃ‰RITÃ‰):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${contextText}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“ DONNÃ‰ES DE L'EXERCICE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
QUESTION POSÃ‰E:
${question}

RÃ‰PONSE CORRECTE ATTENDUE (RÃ‰FÃ‰RENCE ABSOLUE):
${correct_answer}

EXPLICATION OFFICIELLE COMPLÃˆTE:
${detailed_explanation}

RÃ‰PONSE FOURNIE PAR L'Ã‰TUDIANT:
"${userAnswer}"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ RÃˆGLES D'Ã‰VALUATION ULTRA STRICTES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1ï¸âƒ£ COMPARAISON EXACTE DE LA RÃ‰PONSE:
   - Compare la rÃ©ponse de l'Ã©tudiant avec la RÃ‰PONSE CORRECTE ATTENDUE
   - VÃ©rifie que le CONCEPT PRINCIPAL est identique (pas approximatif)
   - Pour APL/ALF/ALS : CE SONT 3 AIDES COMPLÃˆTEMENT DIFFÃ‰RENTES
     * APL â‰  ALF â‰  ALS (AUCUNE confusion acceptÃ©e)
     * Si attendu = "ALS" et rÃ©ponse = "APL" â†’ FAUX (score 0-20)
     * Si attendu = "APL" et rÃ©ponse = "ALF" â†’ FAUX (score 0-20)
     * Si attendu = "ALF" et rÃ©ponse = "ALS" â†’ FAUX (score 0-20)

2ï¸âƒ£ VÃ‰RIFICATION FACTUELLE CONTRE LE CONTEXTE RAG:
   - Consulte le CONTEXTE DOCUMENTAIRE OFFICIEL ci-dessus
   - Chaque affirmation de l'Ã©tudiant DOIT Ãªtre validÃ©e par le contexte
   - Si l'Ã©tudiant dit quelque chose non prÃ©sent dans le contexte â†’ INCORRECT
   - Si l'Ã©tudiant contredit le contexte â†’ INCORRECT (score 0-30)

3ï¸âƒ£ CRITÃˆRES DE CONFORMITÃ‰ (TOUS obligatoires pour score > 80):
   âœ“ Type d'aide mentionnÃ© = RÃ©ponse correcte attendue
   âœ“ Justification alignÃ©e avec l'explication officielle
   âœ“ Aucune contradiction avec le contexte documentaire
   âœ“ Terminologie prÃ©cise (pas de flou, pas d'approximation)
   âœ“ Logique correcte (si justification fournie)

4ï¸âƒ£ VARIATIONS ACCEPTABLES (SEULEMENT):
   Pour APL: "APL", "Aide PersonnalisÃ©e au Logement", "l'APL", "aide personnalisÃ©e"
   Pour ALF: "ALF", "Allocation de Logement Familiale", "l'ALF", "allocation familiale"
   Pour ALS: "ALS", "Allocation de Logement Sociale", "l'ALS", "allocation sociale"
   âš ï¸ Toute autre variation = vÃ©rifier strictement dans le contexte

5ï¸âƒ£ GRILLE DE NOTATION STRICTE:
   100%: RÃ©ponse PARFAITE (type exact + justification complÃ¨te et exacte)
   90-99%: RÃ©ponse correcte + justification bonne mais pourrait Ãªtre plus prÃ©cise
   70-89%: Type correct + justification partielle ou imprÃ©cise
   50-69%: Type correct mais justification manquante ou incorrecte
   30-49%: Type correct mais erreurs factuelles dans la justification
   0-29%: Type d'aide INCORRECT ou erreur factuelle majeure

6ï¸âƒ£ CAS AUTOMATIQUEMENT INCORRECTS (score â‰¤ 30):
   âŒ Confusion APL/ALF/ALS
   âŒ Contradiction directe avec le contexte documentaire
   âŒ Invention de faits non prÃ©sents dans le cours
   âŒ Erreur sur les critÃ¨res d'Ã©ligibilitÃ©
   âŒ Mauvaise comprÃ©hension des concepts de base

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸŽ¯ PROCESSUS D'Ã‰VALUATION (SUIS CET ORDRE):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ã‰TAPE 1: Compare le TYPE d'aide
- RÃ©ponse attendue: ${correct_answer}
- RÃ©ponse Ã©tudiant: ${userAnswer}
- Est-ce identique ? OUI/NON

Ã‰TAPE 2: VÃ©rifie dans le CONTEXTE DOCUMENTAIRE
- Les affirmations de l'Ã©tudiant sont-elles validÃ©es par le contexte ?
- Y a-t-il des contradictions ?

Ã‰TAPE 3: Compare avec l'EXPLICATION OFFICIELLE
- La logique de l'Ã©tudiant suit-elle l'explication officielle ?
- Manque-t-il des Ã©lÃ©ments essentiels ?

Ã‰TAPE 4: Attribue le score selon la grille stricte

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“¤ FORMAT DE RÃ‰PONSE OBLIGATOIRE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RÃ©ponds UNIQUEMENT avec un JSON valide (sans markdown, sans \`\`\`json):
{
  "is_correct": true si score >= 90, false sinon,
  "score": 0-100 (nombre entier),
  "feedback": "Explication DÃ‰TAILLÃ‰E et PÃ‰DAGOGIQUE de l'Ã©valuation (2-4 phrases). Si incorrect, explique PRÃ‰CISÃ‰MENT pourquoi en citant le contexte documentaire. Si correct, fÃ©licite et rÃ©sume les points clÃ©s.",
  "sources_used": ["liste des modules utilisÃ©s"]
}

âš ï¸ RAPPEL FINAL: Sois IMPITOYABLE sur la prÃ©cision mais PÃ‰DAGOGIQUE dans le feedback.
NOTE: L'Ã©tudiant pourra poser des questions de suivi dans un chat libre aprÃ¨s le feedback.`;

        // Call OpenAI for evaluation with STRICT parameters
        const completion = await openai.chat.completions.create({
            model: 'gpt-3.5-turbo',
            messages: [
                {
                    role: 'system',
                    content: 'Tu es un CORRECTEUR STRICT et RIGOUREUX. Suis EXACTEMENT les instructions. RÃ©ponds UNIQUEMENT avec du JSON valide, sans markdown, sans commentaire supplÃ©mentaire.'
                },
                {
                    role: 'user',
                    content: evaluationPrompt
                }
            ],
            temperature: 0.1, // TRÃˆS LOW temperature pour Ã©valuation ultra-consistante et stricte
            max_tokens: 600 // Plus de tokens pour feedback dÃ©taillÃ©
        });

        const responseText = completion.choices[0].message.content.trim();

        // Parse JSON response
        let evaluation;
        try {
            // Remove markdown code blocks if present
            const cleanedResponse = responseText.replace(/```json\n?/g, '').replace(/```\n?/g, '');
            evaluation = JSON.parse(cleanedResponse);
        } catch (parseError) {
            console.error('Failed to parse LLM response:', responseText);
            throw new Error('Invalid JSON response from LLM');
        }

        return {
            is_correct: evaluation.is_correct,
            score: evaluation.score,
            feedback: evaluation.feedback,
            follow_up_question: evaluation.follow_up_question || null,
            sources: contexts.map(ctx => ({
                module: ctx.module,
                section: ctx.section,
                score: ctx.score
            })),
            sources_used: evaluation.sources_used || []
        };

*/

/**
 * Generate a hint for an exercise using RAG context
 */
async function generateHint(exerciseData, attemptNumber = 1) {
    try {
        const { question, hints } = exerciseData;

        // If we have predefined hints, use them first
        if (hints && hints.length > 0 && attemptNumber <= hints.length) {
            return {
                hint: hints[attemptNumber - 1],
                type: 'predefined'
            };
        }

        // Otherwise, generate a hint using RAG context
        const contexts = await searchExerciseContext(question, exerciseData.correct_answer, 2);

        const contextText = contexts
            .map((ctx) => ctx.text)
            .join('\n\n');

        const hintPrompt = `GÃ©nÃ¨re un indice pÃ©dagogique (sans donner la rÃ©ponse) pour cette question:

Question: ${question}

Contexte: ${contextText}

Indice (1 phrase):`;

        const completion = await openai.chat.completions.create({
            model: 'gpt-3.5-turbo',
            messages: [
                { role: 'system', content: 'Tu es un tuteur pÃ©dagogue. Donne un indice subtil sans rÃ©vÃ©ler la rÃ©ponse.' },
                { role: 'user', content: hintPrompt }
            ],
            temperature: 0.7,
            max_tokens: 100
        });

        return {
            hint: completion.choices[0].message.content.trim(),
            type: 'generated'
        };

    } catch (error) {
        console.error('Error generating hint:', error);
        return {
            hint: "Relisez attentivement la question et pensez aux critÃ¨res principaux.",
            type: 'fallback'
        };
    }
}

/**
 * Provide pedagogical clarification without giving the answer
 */
async function provideClarification(exerciseData, userQuestion, conversationHistory = [], questionCount = 0) {
    try {
        const { question, correct_answer, detailed_explanation } = exerciseData;

        // Get relevant context from RAG
        const contexts = await searchExerciseContext(question + " " + userQuestion, correct_answer);

        console.log(`ðŸ’¬ Clarification demandÃ©e pour: "${userQuestion}"`);

        // Build context string
        const contextText = contexts
            .map((ctx, i) => `[Context ${i + 1} - ${ctx.module}]\n${ctx.text}`)
            .join('\n\n');

        // Build conversation history string
        const historyText = conversationHistory
            .map(msg => `${msg.role === 'user' ? 'Ã‰TUDIANT' : 'TUTEUR'}: ${msg.content}`)
            .join('\n');

        // Determine if we should suggest answering
        const shouldSuggestAnswering = questionCount >= 3 && (questionCount % 3 === 0);

        // Build clarification prompt
        const clarificationPrompt = `Tu es un TUTEUR CAF bienveillant et pÃ©dagogue.

QUESTION DE L'EXERCICE:
${question}

CONTEXTE DOCUMENTAIRE OFFICIEL:
${contextText}

${historyText ? `HISTORIQUE DE LA CONVERSATION:\n${historyText}\n` : ''}

L'Ã‰TUDIANT DEMANDE MAINTENANT:
"${userQuestion}"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ RÃˆGLES STRICTES POUR LES CLARIFICATIONS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. EXPLIQUE les concepts, termes techniques, rÃ¨gles demandÃ©s
2. BASE-TOI UNIQUEMENT sur le CONTEXTE DOCUMENTAIRE ci-dessus
3. NE RÃ‰VÃˆLE JAMAIS la rÃ©ponse finale Ã  la question de l'exercice
4. DONNE des indices subtils, des pistes de rÃ©flexion, mais PAS la solution
5. SOIS encourageant et pÃ©dagogique
6. RÃ‰PONDS en 2-4 phrases maximum (sois concis)
7. Si la question de l'Ã©tudiant est hors sujet ou n'a pas de rapport avec l'exercice, redirige-le vers le sujet

${shouldSuggestAnswering ? '\n8. IMPORTANT: Ã€ la fin de ta rÃ©ponse, ajoute sur une nouvelle ligne: "ðŸ’¡ Tu as posÃ© plusieurs bonnes questions ! Tu sembles avoir compris les concepts clÃ©s. PrÃªt Ã  rÃ©pondre ?"' : ''}

EXEMPLE DE BON COMPORTEMENT:
Question: "C'est quoi la zone 1 ?"
âœ… BON: "La zone 1 correspond aux grandes agglomÃ©rations comme Paris, Lyon, Marseille. C'est une classification gÃ©ographique qui impacte les plafonds de loyer."
âŒ MAUVAIS: "La rÃ©ponse Ã  l'exercice est que Marc aura une rÃ©duction de l'aide..."

RÃ‰PONDS MAINTENANT Ã  la question de l'Ã©tudiant:`;

        // Call OpenAI for clarification
        const completion = await openai.chat.completions.create({
            model: 'gpt-3.5-turbo',
            messages: [
                {
                    role: 'system',
                    content: 'Tu es un tuteur pÃ©dagogue CAF. Tu aides Ã  comprendre les concepts SANS donner la rÃ©ponse finale. Sois concis et encourageant.'
                },
                {
                    role: 'user',
                    content: clarificationPrompt
                }
            ],
            temperature: 0.7, // Plus conversationnel que l'Ã©valuation
            max_tokens: 300
        });

        const clarification = completion.choices[0].message.content.trim();

        return {
            clarification,
            sources: contexts.map(ctx => ({
                module: ctx.module,
                section: ctx.section,
                score: ctx.score
            })),
            shouldSuggestAnswering
        };

    } catch (error) {
        console.error('Error providing clarification:', error);
        throw error;
    }
}

/**
 * Provide clarification AFTER answer submission (post-feedback discussion)
 * This can be more open since the answer has already been revealed
 */
async function provideFeedbackClarification(exerciseData, userQuestion, evaluation, conversationHistory = []) {
    try {
        const { question, correct_answer, detailed_explanation } = exerciseData;

        // Get relevant context from RAG
        const contexts = await searchExerciseContext(question + " " + userQuestion + " " + correct_answer, correct_answer);

        console.log(`ðŸ’¬ Discussion post-feedback pour: "${userQuestion}"`);

        // Build context string
        const contextText = contexts
            .map((ctx, i) => `[Context ${i + 1} - ${ctx.module}]\n${ctx.text}`)
            .join('\n\n');

        // Build conversation history string
        const historyText = conversationHistory
            .map(msg => `${msg.role === 'user' ? 'Ã‰TUDIANT' : 'TUTEUR'}: ${msg.content}`)
            .join('\n');

        // Build feedback clarification prompt
        const feedbackPrompt = `Tu es un TUTEUR CAF bienveillant et pÃ©dagogue.

CONTEXTE DE L'EXERCICE:
Question: ${question}
RÃ©ponse correcte: ${correct_answer}
Explication: ${detailed_explanation}

Ã‰VALUATION DE L'Ã‰TUDIANT:
- RÃ©ponse correcte: ${evaluation.is_correct ? 'OUI âœ…' : 'NON âŒ'}
- Feedback donnÃ©: ${evaluation.feedback}

CONTEXTE DOCUMENTAIRE OFFICIEL:
${contextText}

${historyText ? `HISTORIQUE DE LA CONVERSATION POST-FEEDBACK:\n${historyText}\n` : ''}

L'Ã‰TUDIANT DEMANDE MAINTENANT:
"${userQuestion}"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ RÃˆGLES POUR LA DISCUSSION POST-FEEDBACK:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. TU PEUX MAINTENANT parler ouvertement de la rÃ©ponse correcte (elle a dÃ©jÃ  Ã©tÃ© rÃ©vÃ©lÃ©e)
2. APPROFONDIS les concepts selon la demande de l'Ã©tudiant
3. DONNE des exemples concrets si demandÃ©
4. CLARIFIE les points confus ou complexes
5. ILLUSTRE avec des cas pratiques
6. RENTRE dans les dÃ©tails techniques si nÃ©cessaire
7. BASE-TOI sur le CONTEXTE DOCUMENTAIRE OFFICIEL
8. SOIS pÃ©dagogique et encourageant
9. RÃ‰PONDS en 3-6 phrases selon la complexitÃ© de la question

EXEMPLES DE BON COMPORTEMENT:

Question: "Peux-tu me donner un exemple concret de dÃ©gressivitÃ© ?"
âœ… BON: "Bien sÃ»r ! Prenons Marc en zone 1 qui paie 1 150 â‚¬ (entre P2 de 1 121,01 â‚¬ et P3 de 1 318,84 â‚¬). Son aide sera rÃ©duite progressivement : pour chaque euro de loyer au-dessus de P2, son aide diminue de 0,75 â‚¬. Donc : 1 150 - 1 121,01 = 28,99 â‚¬ au-dessus, soit une rÃ©duction de 21,74 â‚¬ sur son aide."

Question: "Quelle est la diffÃ©rence entre APL et ALF ?"
âœ… BON: "L'APL s'applique aux logements conventionnÃ©s (avec accord entre le propriÃ©taire et l'Ã‰tat), quelle que soit la situation familiale. L'ALF concerne les logements NON conventionnÃ©s mais nÃ©cessite une composition familiale spÃ©cifique : couple mariÃ©/pacsÃ© depuis moins de 5 ans, ou enfants/personnes Ã  charge. Si le logement est non conventionnÃ© ET que la personne n'a pas de charge familiale, c'est l'ALS qui s'applique."

Question: "Pourquoi cette rÃ¨gle existe ?"
âœ… BON: "Cette rÃ¨gle vise Ã  rÃ©guler les aides en fonction du marchÃ© locatif. Les seuils P2 et P3 Ã©vitent que l'aide encourage des loyers trop Ã©levÃ©s. Au-delÃ  de P2, l'aide diminue progressivement (dÃ©gressivitÃ©) pour inciter Ã  chercher des logements au loyer raisonnable, tout en continuant Ã  aider jusqu'au plafond P3."

RÃ‰PONDS MAINTENANT Ã  la question de l'Ã©tudiant:`;

        // Call OpenAI for feedback clarification
        const completion = await openai.chat.completions.create({
            model: 'gpt-3.5-turbo',
            messages: [
                {
                    role: 'system',
                    content: 'Tu es un tuteur pÃ©dagogue CAF expert. L\'Ã©tudiant a dÃ©jÃ  reÃ§u son Ã©valuation, tu peux maintenant approfondir librement. Sois dÃ©taillÃ©, pÃ©dagogique et utilise des exemples concrets.'
                },
                {
                    role: 'user',
                    content: feedbackPrompt
                }
            ],
            temperature: 0.7,
            max_tokens: 500 // Plus de tokens pour des explications dÃ©taillÃ©es
        });

        const clarification = completion.choices[0].message.content.trim();

        return {
            clarification,
            sources: contexts.map(ctx => ({
                module: ctx.module,
                section: ctx.section,
                score: ctx.score
            }))
        };

    } catch (error) {
        console.error('Error providing feedback clarification:', error);
        throw error;
    }
}

module.exports = {
    evaluateAnswer,
    generateHint,
    searchExerciseContext,
    provideClarification,
    provideFeedbackClarification
};

